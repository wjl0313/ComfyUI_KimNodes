import torch
import numpy as np
from PIL import Image
from typing import List, Tuple, Dict
import logging

logger = logging.getLogger(__name__)

class Image_List_Deduplicator:
    """
    å¯¹è¾“å…¥çš„å›¾ç‰‡åˆ—è¡¨è¿›è¡Œå»é‡ï¼Œæ”¯æŒè¿‡æ»¤ç›¸ä¼¼å›¾ç‰‡ã€‚
    ä½¿ç”¨å¤šç§å“ˆå¸Œç®—æ³•çš„ç»„åˆæ¥æ£€æµ‹ç›¸ä¼¼å›¾ç‰‡ï¼š
    - Average Hash (aHash)ï¼šåŸºäºå¹³å‡ç°åº¦å€¼
    - Perceptual Hash (pHash)ï¼šåŸºäºDCTå˜æ¢
    - Difference Hash (dHash)ï¼šåŸºäºç›¸é‚»åƒç´ å·®å¼‚
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
                "similarity_threshold": ("FLOAT", {
                    "default": 0.95,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "display": "number"
                }),
                "hash_size": ("INT", {
                    "default": 16,
                    "min": 8,
                    "max": 64,
                    "step": 1,
                    "display": "number"
                }),
                "keep_best_quality": ("BOOLEAN", {
                    "default": True,
                    "label_on": "ä¿ç•™æœ€é«˜è´¨é‡",
                    "label_off": "ä¿ç•™ç¬¬ä¸€å¼ "
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "INT")
    RETURN_NAMES = ("unique_images", "removed_count")
    FUNCTION = "deduplicate_images"
    CATEGORY = "ğŸ’ Kim-Nodes/ğŸ–ï¸å›¾åƒå¤„ç†"
    
    # è¾“å…¥è¾“å‡ºä¸ºåˆ—è¡¨
    INPUT_IS_LIST = True
    OUTPUT_IS_LIST = (True, False)
    
    def tensor_to_pil(self, tensor_image: torch.Tensor) -> Image.Image:
        """å°†å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ"""
        # ç¡®ä¿å¼ é‡åœ¨CPUä¸Š
        tensor_image = tensor_image.cpu()
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ (H, W, C)
        numpy_image = (tensor_image * 255).clamp(0, 255).numpy().astype(np.uint8)
        # å¦‚æœæ˜¯RGBå›¾åƒ
        if numpy_image.shape[-1] == 3:
            return Image.fromarray(numpy_image, mode='RGB')
        # å¦‚æœæ˜¯RGBAå›¾åƒ
        elif numpy_image.shape[-1] == 4:
            return Image.fromarray(numpy_image, mode='RGBA')
        # å¦‚æœæ˜¯ç°åº¦å›¾åƒ
        elif len(numpy_image.shape) == 2:
            return Image.fromarray(numpy_image, mode='L')
        else:
            raise ValueError(f"Unsupported image shape: {numpy_image.shape}")
    
    def average_hash(self, image: Image.Image, hash_size: int = 16) -> str:
        """è®¡ç®—å¹³å‡å“ˆå¸Œ"""
        # è°ƒæ•´å›¾åƒå¤§å°å¹¶è½¬æ¢ä¸ºç°åº¦
        img = image.convert('L').resize((hash_size, hash_size), Image.Resampling.LANCZOS)
        pixels = np.array(img)
        
        # è®¡ç®—å¹³å‡å€¼
        avg = pixels.mean()
        
        # ç”Ÿæˆå“ˆå¸Œ
        hash_bits = pixels > avg
        return ''.join(str(int(bit)) for bit in hash_bits.flatten())
    
    def difference_hash(self, image: Image.Image, hash_size: int = 16) -> str:
        """è®¡ç®—å·®å¼‚å“ˆå¸Œ"""
        # è°ƒæ•´å›¾åƒå¤§å°ï¼ˆå®½åº¦å¤šä¸€ä¸ªåƒç´ ç”¨äºè®¡ç®—å·®å¼‚ï¼‰
        img = image.convert('L').resize((hash_size + 1, hash_size), Image.Resampling.LANCZOS)
        pixels = np.array(img)
        
        # è®¡ç®—ç›¸é‚»åƒç´ çš„å·®å¼‚
        diff = pixels[:, 1:] > pixels[:, :-1]
        
        # ç”Ÿæˆå“ˆå¸Œ
        return ''.join(str(int(bit)) for bit in diff.flatten())
    
    def perceptual_hash(self, image: Image.Image, hash_size: int = 16) -> str:
        """è®¡ç®—æ„ŸçŸ¥å“ˆå¸Œï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        # å¯¹äºè¾ƒå¤§çš„hash_sizeï¼Œä½¿ç”¨æ›´å¤§çš„åˆå§‹å›¾åƒ
        img_size = max(64, hash_size * 4)
        img = image.convert('L').resize((img_size, img_size), Image.Resampling.LANCZOS)
        pixels = np.array(img, dtype=np.float32)
        
        # ç®€å•çš„å¹³æ»‘å¤„ç†ï¼ˆä½¿ç”¨å‡å€¼æ»¤æ³¢ä»£æ›¿é«˜æ–¯æ»¤æ³¢ï¼‰
        kernel_size = 3
        pad = kernel_size // 2
        padded = np.pad(pixels, pad, mode='edge')
        smoothed = np.zeros_like(pixels)
        
        for i in range(pixels.shape[0]):
            for j in range(pixels.shape[1]):
                smoothed[i, j] = padded[i:i+kernel_size, j:j+kernel_size].mean()
        
        pixels = smoothed
        
        # ç®€åŒ–çš„DCTå®ç°ï¼šä½¿ç”¨åˆ†å—å¹¶è®¡ç®—æ¢¯åº¦
        # å°†å›¾åƒåˆ†æˆhash_size x hash_sizeçš„å—
        block_size = img_size // hash_size
        dct_like = np.zeros((hash_size, hash_size))
        
        for i in range(hash_size):
            for j in range(hash_size):
                # è·å–å—
                block = pixels[i*block_size:(i+1)*block_size, j*block_size:(j+1)*block_size]
                # è®¡ç®—å—çš„ç‰¹å¾ï¼ˆä½¿ç”¨æ ‡å‡†å·®æ¥æ•æ‰çº¹ç†ä¿¡æ¯ï¼‰
                mean_val = block.mean()
                std_val = block.std()
                # ç»“åˆå‡å€¼å’Œæ ‡å‡†å·®
                dct_like[i, j] = mean_val + std_val * 0.5
        
        # è®¡ç®—ä¸­ä½æ•°è€Œä¸æ˜¯å¹³å‡å€¼ï¼ˆæ›´é²æ£’ï¼‰
        median_val = np.median(dct_like)
        
        # ç”Ÿæˆå“ˆå¸Œ
        hash_bits = dct_like > median_val
        return ''.join(str(int(bit)) for bit in hash_bits.flatten())
    
    def compute_hash_tuple(self, image: Image.Image, hash_size: int) -> Tuple[str, str, str]:
        """
        è®¡ç®—å›¾åƒçš„å¤šç§å“ˆå¸Œå€¼ç»„åˆ
        è¿”å›: (average_hash, perceptual_hash, difference_hash)
        """
        # è®¡ç®—ä¸‰ç§å“ˆå¸Œï¼Œæ¯ç§ä½¿ç”¨åŸå§‹å›¾åƒä»¥ä¿ç•™æ›´å¤šç»†èŠ‚
        ahash = self.average_hash(image, hash_size)
        phash = self.perceptual_hash(image, hash_size)
        dhash = self.difference_hash(image, hash_size)
        
        return (ahash, phash, dhash)
    
    def hamming_distance(self, hash1: str, hash2: str) -> int:
        """è®¡ç®—ä¸¤ä¸ªå“ˆå¸Œå­—ç¬¦ä¸²ä¹‹é—´çš„æ±‰æ˜è·ç¦»"""
        if len(hash1) != len(hash2):
            return max(len(hash1), len(hash2))
        return sum(c1 != c2 for c1, c2 in zip(hash1, hash2))
    
    def combined_hamming_distance(self, hash_tuple1: Tuple[str, str, str], 
                                 hash_tuple2: Tuple[str, str, str]) -> int:
        """è®¡ç®—ç»„åˆå“ˆå¸Œçš„æ€»æ±‰æ˜è·ç¦»"""
        total_distance = 0
        for h1, h2 in zip(hash_tuple1, hash_tuple2):
            total_distance += self.hamming_distance(h1, h2)
        return total_distance
    
    def are_similar(self, hash_tuple1: Tuple[str, str, str], 
                   hash_tuple2: Tuple[str, str, str], 
                   threshold: float, hash_size: int) -> bool:
        """
        åˆ¤æ–­ä¸¤ä¸ªå›¾åƒæ˜¯å¦ç›¸ä¼¼
        threshold: 0.0-1.0 çš„ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶Šæ¥è¿‘1.0è¦æ±‚è¶Šç›¸ä¼¼
        """
        # åˆ†åˆ«è®¡ç®—æ¯ç§å“ˆå¸Œçš„ç›¸ä¼¼åº¦
        similarities = []
        hash_names = ['average', 'perceptual', 'difference']
        
        for idx, (h1, h2) in enumerate(zip(hash_tuple1, hash_tuple2)):
            if len(h1) != len(h2):
                logger.warning(f"{hash_names[idx]} hashé•¿åº¦ä¸åŒ¹é…: {len(h1)} vs {len(h2)}")
                return False
            
            # è®¡ç®—æ±‰æ˜è·ç¦»
            distance = self.hamming_distance(h1, h2)
            # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆ0-1èŒƒå›´ï¼‰
            max_distance = len(h1)
            similarity = 1.0 - (distance / max_distance)
            similarities.append(similarity)
        
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨ç›¸ä¼¼åº¦è¾ƒé«˜æ—¶ï¼‰
        weighted_similarity = sum(s * w for s, w in zip(similarities, [0.25, 0.5, 0.25]))
        if weighted_similarity > 0.8:
            logger.info(f"é«˜ç›¸ä¼¼åº¦å¯¹æ¯” - A:{similarities[0]:.3f}, P:{similarities[1]:.3f}, D:{similarities[2]:.3f}, åŠ æƒ:{weighted_similarity:.3f}, é˜ˆå€¼:{threshold:.2f}")
        
        # æ›´ä¸¥æ ¼çš„åˆ¤æ–­é€»è¾‘
        if threshold >= 0.99:
            # æé«˜é˜ˆå€¼ï¼šè¦æ±‚æ‰€æœ‰å“ˆå¸Œéƒ½éå¸¸ç›¸ä¼¼
            return all(s >= 0.98 for s in similarities)
        elif threshold >= 0.95:
            # é«˜é˜ˆå€¼ï¼šè‡³å°‘ä¸¤ç§å“ˆå¸Œéå¸¸ç›¸ä¼¼ï¼Œä¸”æ²¡æœ‰å“ˆå¸Œç›¸ä¼¼åº¦è¿‡ä½
            high_similarity_count = sum(1 for s in similarities if s >= threshold)
            min_similarity = min(similarities)
            return high_similarity_count >= 2 and min_similarity >= (threshold - 0.15)
        elif threshold >= 0.90:
            # ä¸­é«˜é˜ˆå€¼ï¼šæ„ŸçŸ¥å“ˆå¸Œå¿…é¡»ç›¸ä¼¼ï¼Œä¸”åŠ æƒå¹³å‡è¾¾æ ‡
            return similarities[1] >= threshold and weighted_similarity >= threshold
        elif threshold >= 0.85:
            # ä¸­é˜ˆå€¼ï¼šè‡³å°‘æœ‰ä¸€ç§å“ˆå¸Œéå¸¸ç›¸ä¼¼ï¼Œä¸”åŠ æƒå¹³å‡è¾¾æ ‡
            max_similarity = max(similarities)
            return max_similarity >= (threshold + 0.1) and weighted_similarity >= threshold
        else:
            # ä½é˜ˆå€¼ï¼šä½¿ç”¨åŠ æƒå¹³å‡ï¼Œä½†è¦æ±‚è‡³å°‘æœ‰ä¸€ç§å“ˆå¸Œè¾¾åˆ°åŸºå‡†
            return weighted_similarity >= threshold and max(similarities) >= threshold
    
    def get_image_quality_score(self, tensor_image: torch.Tensor) -> Tuple[int, int]:
        """
        è®¡ç®—å›¾åƒè´¨é‡åˆ†æ•°
        è¿”å›: (åˆ†è¾¨ç‡, æ•°æ®å¤§å°ä¼°ç®—)
        """
        height, width = tensor_image.shape[0], tensor_image.shape[1]
        resolution = height * width
        # ä¼°ç®—æ•°æ®å¤§å°ï¼ˆåŸºäºå¼ é‡å…ƒç´ æ•°é‡ï¼‰
        data_size = tensor_image.numel()
        return (resolution, data_size)
    
    def deduplicate_images(self, images, similarity_threshold, hash_size, keep_best_quality):
        """
        å¯¹å›¾ç‰‡åˆ—è¡¨è¿›è¡Œå»é‡
        
        Args:
            images: è¾“å…¥å›¾ç‰‡tensoråˆ—è¡¨
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰
            hash_size: å“ˆå¸Œå¤§å°
            keep_best_quality: æ˜¯å¦ä¿ç•™æœ€é«˜è´¨é‡çš„å›¾ç‰‡
            
        Returns:
            tuple: (å»é‡åçš„å›¾ç‰‡åˆ—è¡¨, ç§»é™¤çš„å›¾ç‰‡æ•°é‡)
        """
        # ç¡®ä¿è¾“å…¥æ˜¯åˆ—è¡¨
        if not isinstance(images, list):
            images = [images]
        
        # è·å–å‚æ•°å€¼ï¼ˆå¤„ç†åˆ—è¡¨è¾“å…¥ï¼‰
        similarity_threshold = similarity_threshold[0] if isinstance(similarity_threshold, list) else similarity_threshold
        hash_size = hash_size[0] if isinstance(hash_size, list) else hash_size
        keep_best_quality = keep_best_quality[0] if isinstance(keep_best_quality, list) else keep_best_quality
        
        # å¦‚æœæ²¡æœ‰å›¾ç‰‡æˆ–åªæœ‰ä¸€å¼ å›¾ç‰‡ï¼Œç›´æ¥è¿”å›
        if len(images) <= 1:
            return (images, 0)
        
        # è®¡ç®—æ‰€æœ‰å›¾åƒçš„å“ˆå¸Œå€¼å’Œè´¨é‡åˆ†æ•°
        image_data = []
        for i, img_tensor in enumerate(images):
            try:
                pil_image = self.tensor_to_pil(img_tensor)
                hash_tuple = self.compute_hash_tuple(pil_image, hash_size)
                quality_score = self.get_image_quality_score(img_tensor)
                image_data.append({
                    'index': i,
                    'tensor': img_tensor,
                    'hash': hash_tuple,
                    'quality': quality_score,
                    'is_duplicate': False
                })
            except Exception as e:
                logger.error(f"å¤„ç†å›¾ç‰‡ {i} æ—¶å‡ºé”™: {str(e)}")
                # å‡ºé”™çš„å›¾ç‰‡ä¿ç•™
                image_data.append({
                    'index': i,
                    'tensor': img_tensor,
                    'hash': None,
                    'quality': (0, 0),
                    'is_duplicate': False
                })
        
        # æŸ¥æ‰¾é‡å¤ç»„
        duplicate_groups = []
        processed = set()
        
        for i in range(len(image_data)):
            if i in processed or image_data[i]['hash'] is None:
                continue
                
            # åˆ›å»ºæ–°çš„é‡å¤ç»„ï¼ŒåªåŒ…å«çœŸæ­£ç›¸ä¼¼çš„å›¾ç‰‡
            group = [i]
            processed.add(i)
            
            # åªä¸å½“å‰å›¾ç‰‡æ¯”è¾ƒï¼Œä¸ä¼ é€’ç›¸ä¼¼æ€§
            for j in range(i + 1, len(image_data)):
                if j in processed or image_data[j]['hash'] is None:
                    continue
                    
                # åªæœ‰ä¸ç¬¬ä¸€å¼ å›¾ç‰‡ç›¸ä¼¼çš„æ‰åŠ å…¥ç»„
                if self.are_similar(image_data[i]['hash'], image_data[j]['hash'], 
                                  similarity_threshold, hash_size):
                    group.append(j)
                    processed.add(j)
            
            if len(group) > 1:
                duplicate_groups.append(group)
                
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        logger.info(f"å‘ç° {len(duplicate_groups)} ä¸ªé‡å¤ç»„")
        for idx, group in enumerate(duplicate_groups):
            logger.info(f"ç»„ {idx + 1}: åŒ…å« {len(group)} å¼ å›¾ç‰‡")
        
        # å¤„ç†é‡å¤ç»„ï¼Œæ ‡è®°è¦åˆ é™¤çš„å›¾ç‰‡
        removed_count = 0
        for group in duplicate_groups:
            if keep_best_quality:
                # æŒ‰è´¨é‡æ’åºï¼Œä¿ç•™æœ€å¥½çš„
                group_data = [(idx, image_data[idx]['quality']) for idx in group]
                # æŒ‰åˆ†è¾¨ç‡å’Œæ•°æ®å¤§å°æ’åºï¼Œæœ€åæŒ‰ç´¢å¼•æ’åºï¼ˆä¿æŒç¨³å®šæ€§ï¼‰
                group_data.sort(key=lambda x: (x[1][0], x[1][1], x[0]))
                # æ ‡è®°é™¤æœ€åä¸€ä¸ªï¼ˆæœ€é«˜è´¨é‡ï¼‰å¤–çš„æ‰€æœ‰å›¾ç‰‡ä¸ºé‡å¤
                for idx, _ in group_data[:-1]:
                    image_data[idx]['is_duplicate'] = True
                    removed_count += 1
            else:
                # ä¿ç•™ç¬¬ä¸€å¼ ï¼Œåˆ é™¤å…¶ä»–
                for idx in group[1:]:
                    image_data[idx]['is_duplicate'] = True
                    removed_count += 1
        
        # æ”¶é›†æœªæ ‡è®°ä¸ºé‡å¤çš„å›¾ç‰‡
        unique_images = []
        for data in image_data:
            if not data['is_duplicate']:
                unique_images.append(data['tensor'])
        
        # å¦‚æœæ‰€æœ‰å›¾ç‰‡éƒ½è¢«æ ‡è®°ä¸ºé‡å¤ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œè‡³å°‘ä¿ç•™ç¬¬ä¸€å¼ 
        if not unique_images and images:
            unique_images = [images[0]]
            removed_count = len(images) - 1
        
        logger.info(f"å»é‡å®Œæˆï¼šåŸå§‹å›¾ç‰‡ {len(images)} å¼ ï¼Œä¿ç•™ {len(unique_images)} å¼ ï¼Œç§»é™¤ {removed_count} å¼ ")
        
        return (unique_images, removed_count) 