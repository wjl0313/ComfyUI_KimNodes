import torch
import numpy as np

class BoundingBox_Cropper:
    """
    æ ¹æ®è¾¹ç•Œæ¡†åæ ‡è£åˆ‡å›¾ç‰‡çš„èŠ‚ç‚¹ã€‚
    å½“bbox_indexä¸º-1æ—¶ï¼Œè¾“å‡ºæ‰€æœ‰æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†å¯¹åº”çš„è£å‰ªå›¾ç‰‡ã€‚
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "bboxes": ("BBOXES", {"forceInput": True}),
                "bbox_index": ("INT", {
                    "default": 0,
                    "min": -1,
                    "max": 100,
                    "step": 1
                })
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "crop_image"
    CATEGORY = "ğŸ’ Kim-Nodes/âœ‚ Crop | è£å‰ªå·¥å…·"
    OUTPUT_IS_LIST = (True,)

    def crop_image(self, image, bboxes, bbox_index=0):
        """
        æ ¹æ®è¾¹ç•Œæ¡†åæ ‡è£åˆ‡å›¾ç‰‡
        
        å‚æ•°:
            image: è¾“å…¥å›¾ç‰‡å¼ é‡ (B,H,W,C)
            bboxes: è¾¹ç•Œæ¡†åæ ‡åˆ—è¡¨
            bbox_index: è¦ä½¿ç”¨çš„è¾¹ç•Œæ¡†ç´¢å¼•ï¼Œ-1è¡¨ç¤ºè¾“å‡ºæ‰€æœ‰è¾¹ç•Œæ¡†
        """
        
        # ç¡®ä¿è¾“å…¥å›¾ç‰‡æ˜¯æ­£ç¡®çš„æ ¼å¼
        if len(image.shape) != 4:
            image = image.unsqueeze(0)
        
        result_images = []
        
        for i in range(len(image)):
            # è·å–å½“å‰å›¾åƒå¯¹åº”çš„è¾¹ç•Œæ¡†
            current_bboxes = bboxes[min(i, len(bboxes)-1)]
            
            # å¦‚æœæ²¡æœ‰è¾¹ç•Œæ¡†ï¼Œè¿”å›åŸå§‹å›¾åƒ
            if len(current_bboxes) == 0:
                result_images.append(image[i].unsqueeze(0))
                continue
            
            # ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœbbox_indexä¸º-1ï¼Œè£åˆ‡æ‰€æœ‰è¾¹ç•Œæ¡†
            if bbox_index == -1:
                for bbox in current_bboxes:
                    # æå–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = bbox
                    
                    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    B, H, W, C = image.shape
                    x1 = max(0, min(x1, W-1))
                    y1 = max(0, min(y1, H-1))
                    x2 = max(x1+1, min(x2, W))
                    y2 = max(y1+1, min(y2, H))
                    
                    # è¿›è¡Œè£åˆ‡
                    cropped = image[i:i+1, y1:y2, x1:x2, :]
                    result_images.append(cropped)
            else:
                # è·å–æŒ‡å®šç´¢å¼•çš„è¾¹ç•Œæ¡†ï¼Œå¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†
                box_idx = min(bbox_index, len(current_bboxes)-1)
                bbox = current_bboxes[box_idx]
                
                # æå–è¾¹ç•Œæ¡†åæ ‡
                x1, y1, x2, y2 = bbox
                
                # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                B, H, W, C = image.shape
                x1 = max(0, min(x1, W-1))
                y1 = max(0, min(y1, H-1))
                x2 = max(x1+1, min(x2, W))
                y2 = max(y1+1, min(y2, H))
                
                # è¿›è¡Œè£åˆ‡
                cropped = image[i:i+1, y1:y2, x1:x2, :]
                result_images.append(cropped)
        
        # è¿”å›å›¾ç‰‡åˆ—è¡¨
        return (result_images,) 