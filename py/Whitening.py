from aiohttp import web
import cv2
import numpy as np
import torch

class Whitening_Node:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "auto_whitening": ("BOOLEAN", {
                    "default": False,
                    "label": "Auto Whitening"
                }),
                "whitening_strength": ("INT", {
                    "default": 50, 
                    "min": 0, 
                    "max": 100, 
                    "step": 1,
                    "lazy": False
                }),
                "Translucent_skin": ("INT", {
                    "default": 10,
                    "min": 0,
                    "max": 20,
                    "step": 1,
                    "lazy": False
                }),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("whitened_image",)
    FUNCTION = "execute"
    CATEGORY = "ğŸŠ Kim-Nodes/ğŸ‘§ğŸ»ç¾é¢œ"

    def __init__(self):
        pass

    def detect_skin(self, img):
        """
        æ£€æµ‹å›¾åƒä¸­çš„çš®è‚¤åŒºåŸŸã€‚
        """
        ycrcb = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)
        min_YCrCb = np.array([0, 133, 77], np.uint8)
        max_YCrCb = np.array([255, 173, 127], np.uint8)
        skin_mask = cv2.inRange(ycrcb, min_YCrCb, max_YCrCb)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        skin_mask = cv2.erode(skin_mask, kernel, iterations=1)
        skin_mask = cv2.dilate(skin_mask, kernel, iterations=1)
        skin_mask = cv2.GaussianBlur(skin_mask, (3, 3), 0)
        return skin_mask

    def generate_whitening_lookup(self, value):
        """
        ç”Ÿæˆç¾ç™½æŸ¥æ‰¾è¡¨
        """
        midtones_add = 0.667 * (1 - ((np.arange(256) - 127.0) / 127) ** 2)
        lookup = np.clip(np.arange(256) + (value * midtones_add).astype(np.int16), 0, 255).astype(np.uint8)
        return lookup

    def analyze_skin_tone(self, img_np):
        """
        æ™ºèƒ½åˆ†æçš®è‚¤çŠ¶å†µï¼ŒåŠ¨æ€è¿”å›å»ºè®®çš„ç¾ç™½å¼ºåº¦
        """
        skin_mask = self.detect_skin(img_np)
        skin_area = cv2.bitwise_and(img_np, img_np, mask=skin_mask)
        
        # è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´è¿›è¡Œåˆ†æ
        lab_img = cv2.cvtColor(skin_area, cv2.COLOR_RGB2LAB)
        l_channel = lab_img[:, :, 0]  # äº®åº¦é€šé“
        a_channel = lab_img[:, :, 1]  # çº¢ç»¿é€šé“
        b_channel = lab_img[:, :, 2]  # é»„è“é€šé“
        
        # è·å–æœ‰æ•ˆçš„çš®è‚¤åƒç´ 
        valid_pixels = (skin_mask > 0)
        if not np.any(valid_pixels):
            return 45  # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°çš®è‚¤ï¼Œè¿”å›ä¸­ç­‰é»˜è®¤å€¼
        
        # åˆ†æäº®åº¦åˆ†å¸ƒ
        l_values = l_channel[valid_pixels]
        mean_l = np.mean(l_values)
        std_l = np.std(l_values)
        
        # åˆ†æè‚¤è‰²
        a_values = a_channel[valid_pixels]
        b_values = b_channel[valid_pixels]
        mean_a = np.mean(a_values)
        mean_b = np.mean(b_values)
        
        # é‡æ–°è°ƒæ•´äº®åº¦åŒºé—´çš„åŸºç¡€å¼ºåº¦ï¼ˆé™ä½äº®å›¾ç‰‡çš„å¤„ç†å¼ºåº¦ï¼‰
        if mean_l > 200:      # è¿‡åº¦æ˜äº®
            base_strength = 5
        elif mean_l > 180:    # éå¸¸äº®
            base_strength = 10
        elif mean_l > 160:    # è¾ƒäº®
            base_strength = 20
        elif mean_l > 140:    # ç¨äº®
            base_strength = 35
        elif mean_l > 120:    # ä¸­ç­‰
            base_strength = 50
        elif mean_l > 100:    # ç¨æš—
            base_strength = 65
        elif mean_l > 80:     # è¾ƒæš—
            base_strength = 75
        else:                # éå¸¸æš—
            base_strength = 85
        
        # è®¡ç®—æš—åŒºæ¯”ä¾‹ï¼ˆæ›´ç²¾ç¡®çš„æš—åŒºåˆ†æï¼‰
        dark_pixels = l_values < 100
        dark_ratio = np.mean(dark_pixels)
        very_dark_pixels = l_values < 80
        very_dark_ratio = np.mean(very_dark_pixels)
        
        # æ ¹æ®æš—åŒºæ¯”ä¾‹è°ƒæ•´å¼ºåº¦
        if very_dark_ratio > 0.3:  # å¤§é¢ç§¯æ·±æš—åŒº
            base_strength += int(very_dark_ratio * 30)
        elif dark_ratio > 0.4:     # å¤§é¢ç§¯æš—åŒº
            base_strength += int(dark_ratio * 20)
        
        # å…‰ç…§å‡åŒ€æ€§åˆ†æï¼ˆæ›´æ¸©å’Œçš„è°ƒæ•´ï¼‰
        if std_l > 45:  # ä¸¥é‡ä¸å‡åŒ€
            base_strength += int(min(std_l - 45, 15))
        elif std_l > 35:  # ä¸­åº¦ä¸å‡åŒ€
            base_strength += int(min(std_l - 35, 8))
        elif std_l > 25:  # è½»åº¦ä¸å‡åŒ€
            base_strength += int(min(std_l - 25, 5))
        
        # è‚¤è‰²è°ƒæ•´ï¼ˆæ›´æ¸©å’Œï¼‰
        if mean_a > 135:  # æ˜æ˜¾åçº¢
            base_strength += 2
        if mean_b > 135:  # æ˜æ˜¾åé»„
            base_strength += 2
        
        # é«˜å…‰ä¿æŠ¤ï¼šå¦‚æœé«˜å…‰åŒºåŸŸï¼ˆL>200ï¼‰å æ¯”è¾ƒå¤§ï¼Œé™ä½ç¾ç™½å¼ºåº¦
        highlight_ratio = np.mean(l_values > 200)
        if highlight_ratio > 0.1:  # å¦‚æœé«˜å…‰åŒºåŸŸè¶…è¿‡10%
            base_strength = max(5, base_strength - int(highlight_ratio * 30))
        
        # ç¡®ä¿æœ€ç»ˆå¼ºåº¦åœ¨åˆç†èŒƒå›´å†…ï¼ˆé™ä½ä¸Šé™ï¼‰
        final_strength = np.clip(base_strength, 5, 85)
        
        # æ‰“å°è¯¦ç»†åˆ†æç»“æœ
        print(f"\nSkin Analysis Results:")
        print(f"Average Brightness: {mean_l:.1f} (L channel)")
        print(f"Brightness Variation: {std_l:.1f}")
        print(f"Dark Area Ratio: {dark_ratio:.2f}")
        print(f"Very Dark Area Ratio: {very_dark_ratio:.2f}")
        print(f"Highlight Area Ratio: {highlight_ratio:.2f}")
        print(f"Red Level: {mean_a:.1f} (a channel)")
        print(f"Yellow Level: {mean_b:.1f} (b channel)")
        print(f"Base Strength: {base_strength}")
        print(f"Final Whitening Strength: {final_strength}")
        
        return final_strength

    def execute(self, image, auto_whitening, whitening_strength, Translucent_skin):
        """
        æ‰§è¡Œç¾ç™½å¤„ç†
        """
        if image is None:
            return (None,)

        img_np = (image.cpu().numpy() * 255).astype(np.uint8)
        img_np = img_np[0]
        
        if auto_whitening:
            whitening_strength = self.analyze_skin_tone(img_np)
            print(f"Auto-detected whitening strength: {whitening_strength}")
        
        # æ£€æµ‹çš®è‚¤åŒºåŸŸ
        skin_mask = self.detect_skin(img_np)
        skin_mask = skin_mask / 255.0
        
        # è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´
        lab_img = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)
        
        # è°ƒæ•´LABé€šé“
        adjusted_lab = lab_img.copy()
        adjusted_lab[:, :, 2] = np.clip(lab_img[:, :, 2] - Translucent_skin * 0.5, 0, 255)
        
        # è½¬æ¢å›RGB
        adjusted_rgb = cv2.cvtColor(adjusted_lab, cv2.COLOR_LAB2RGB)
        
        # ä½¿ç”¨æ©ç æ··åˆåŸå§‹å›¾åƒå’Œè°ƒæ•´åçš„å›¾åƒ
        skin_mask = np.expand_dims(skin_mask, axis=2)
        img_np = (img_np * (1 - skin_mask) + adjusted_rgb * skin_mask).astype(np.uint8)
        
        # åº”ç”¨ç¾ç™½æ•ˆæœ
        lookup = self.generate_whitening_lookup(whitening_strength)
        result = img_np.copy()
        for c in range(3):
            result[:, :, c] = lookup[img_np[:, :, c].astype(np.uint8)]
        
        # è½¬æ¢å›PyTorchå¼ é‡
        result_tensor = torch.from_numpy(result.astype(np.float32) / 255.0).unsqueeze(0)
        
        return (result_tensor,)

