import numpy as np
import torch
import cv2
from PIL import Image
import torch.nn.functional as F

def images_process(images):
    """å¤„ç†å›¾åƒï¼Œå°†å…¶è½¬æ¢ä¸ºPILå›¾åƒ"""
    if isinstance(images, torch.Tensor):
        # å¦‚æœæ˜¯å¼ é‡ï¼Œè½¬æ¢ä¸ºPILå›¾åƒ
        images = images.cpu().numpy()
        if len(images.shape) == 4:
            # æ‰¹å¤„ç†å›¾åƒ
            processed_images = []
            for img in images:
                # å°†å€¼èŒƒå›´ä»[0,1]è½¬æ¢ä¸º[0,255]
                img = (img * 255).astype(np.uint8)
                # å¦‚æœå›¾åƒæ˜¯RGBæˆ–RGBAæ ¼å¼
                if img.shape[2] == 3:
                    img = Image.fromarray(img, 'RGB')
                elif img.shape[2] == 4:
                    img = Image.fromarray(img, 'RGBA')
                elif img.shape[2] == 1:
                    img = Image.fromarray(img.squeeze(), 'L')
                processed_images.append(img)
            return processed_images
        else:
            # å•å¼ å›¾åƒ
            img = (images * 255).astype(np.uint8)
            if images.shape[2] == 3:
                return [Image.fromarray(img, 'RGB')]
            elif images.shape[2] == 4:
                return [Image.fromarray(img, 'RGBA')]
            elif images.shape[2] == 1:
                return [Image.fromarray(img.squeeze(), 'L')]
    elif isinstance(images, list):
        # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œæ£€æŸ¥æ¯ä¸ªå…ƒç´ 
        processed_images = []
        for img in images:
            if isinstance(img, torch.Tensor):
                img = img.cpu().numpy()
                img = (img * 255).astype(np.uint8)
                if img.shape[2] == 3:
                    img = Image.fromarray(img, 'RGB')
                elif img.shape[2] == 4:
                    img = Image.fromarray(img, 'RGBA')
                elif img.shape[2] == 1:
                    img = Image.fromarray(img.squeeze(), 'L')
            processed_images.append(img)
        return processed_images
    elif isinstance(images, Image.Image):
        # å¦‚æœæ˜¯å•ä¸ªPILå›¾åƒ
        return [images]
    else:
        raise ValueError("Unsupported image type")

def _split_mask(image, mask, padding=10, filtration_area=0.0025):
    """æ ¹æ®maskåˆ†å‰²å›¾åƒå…ƒç´ """
    # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
    image_np = np.array(image)
    
    # ç¡®ä¿maskæ˜¯å•é€šé“uint8ç±»å‹å›¾åƒ
    if isinstance(mask, np.ndarray):
        mask_np = mask
    else:
        mask_np = np.array(mask)
    
    # ç¡®ä¿maskæ˜¯å•é€šé“å›¾åƒ
    if len(mask_np.shape) > 2:
        mask_np = mask_np[:, :, 0] if mask_np.shape[-1] > 1 else mask_np.squeeze()
    
    # ç¡®ä¿maskæ˜¯uint8ç±»å‹
    if mask_np.dtype != np.uint8:
        mask_np = (mask_np * 255).astype(np.uint8)
    
    # äºŒå€¼åŒ–å¤„ç†
    _, mask_binary = cv2.threshold(mask_np, 127, 255, cv2.THRESH_BINARY)
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    # æ’é™¤è½®å»“é¢ç§¯å æ¯”å°äºfiltration_areaçš„è½®å»“
    contours = [contour for contour in contours if cv2.contourArea(contour) > filtration_area * image_np.shape[0] * image_np.shape[1]]
    result_images = []
    
    for contour in contours:
        # è·å–è¾¹ç•Œæ¡†
        x, y, w, h = cv2.boundingRect(contour)
        
        # æ·»åŠ padding
        x = max(0, x - padding)
        y = max(0, y - padding)
        w = min(image_np.shape[1] - x, w + 2 * padding)
        h = min(image_np.shape[0] - y, h + 2 * padding)
        
        # åˆ›å»ºé€æ˜èƒŒæ™¯
        rgba = np.zeros((h, w, 4), dtype=np.uint8)
        
        # å¤åˆ¶RGBé€šé“å’ŒåŸå§‹alphaé€šé“
        if image_np.shape[-1] == 4:  # å¦‚æœåŸå›¾æœ‰alphaé€šé“
            rgba[:, :, :4] = image_np[y:y+h, x:x+w, :4]
        else:  # å¦‚æœåŸå›¾åªæœ‰RGBé€šé“
            rgba[:, :, :3] = image_np[y:y+h, x:x+w, :3]
        
        # åˆ›å»ºå½“å‰è½®å»“çš„mask
        contour_mask = np.zeros_like(mask_binary)
        cv2.drawContours(contour_mask, [contour], -1, 255, -1)
        
        # åªå–å½“å‰è½®å»“å†…çš„åŒºåŸŸä½œä¸ºalphaé€šé“
        alpha = contour_mask[y:y+h, x:x+w]
        
        # å¦‚æœåŸå›¾æœ‰alphaé€šé“ï¼Œéœ€è¦å°†åŸå§‹alphaå’Œè½®å»“maskç»“åˆ
        if image_np.shape[-1] == 4:
            original_alpha = image_np[y:y+h, x:x+w, 3]
            rgba[:, :, 3] = cv2.bitwise_and(original_alpha, alpha)
        else:
            rgba[:, :, 3] = alpha
        
        # å°†numpyæ•°ç»„è½¬æ¢ä¸ºPILå›¾åƒ
        result_image = Image.fromarray(rgba)
        result_images.append(result_image)
    
    return result_images

def process_mask(mask):
    if isinstance(mask, torch.Tensor):
        # å¤„ç†[1, 1, H, W]æ ¼å¼
        if len(mask.shape) == 4 and mask.shape[0] == 1 and mask.shape[1] == 1:
            mask = mask[0, 0]
        # å¤„ç†[1, H, W]æ ¼å¼
        elif len(mask.shape) == 3 and mask.shape[0] == 1:
            mask = mask[0]
            
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶è°ƒæ•´å€¼èŒƒå›´
        mask_np = (mask.cpu().numpy() * 255).astype(np.uint8)
        return mask_np  # ç›´æ¥è¿”å›uint8ç±»å‹çš„numpyæ•°ç»„
    
    return mask

class Split_Mask:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "mask": ("MASK",),
                "padding": ("INT", {"default": 10, "min": 0, "max": 100, "step": 1}),
                "filtration_area": ("FLOAT", {"default": 0.0025, "min": 0, "max": 1, "step": 0.0001}),
            },
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    OUTPUT_IS_LIST = (True,)
    FUNCTION = "split_mask"
    CATEGORY = "ğŸ’ Kim-Nodes/ğŸ”²Mask_Tools | è’™æ¿å·¥å…·"

    def split_mask(self, image, mask, padding=10, filtration_area=0.0025):
        # å¤„ç†è¾“å…¥å›¾åƒ
        image = images_process(image)[0]
        
        # å¤„ç†mask
        mask = process_mask(mask)
        
        # åˆ†å‰²maskå…ƒç´ 
        result_images = _split_mask(image, mask, padding, filtration_area)
        
        # å¤„ç†ç»“æœå›¾åƒ
        processed_images = []
        for result_image in result_images:
            # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
            result_np = np.array(result_image).astype(np.float32) / 255
            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            result_np = np.expand_dims(result_np, axis=0)
            # è½¬æ¢ä¸ºå¼ é‡
            img = torch.from_numpy(result_np)
            processed_images.append(img)
            
        return (processed_images,)