import os  
import logging
from PIL import Image, PngImagePlugin
from typing import Tuple, Optional
import torch
import numpy as np

def tensor2pil(image_tensor: torch.Tensor) -> Image.Image:
    """
    å°†å›¾åƒå¼ é‡è½¬æ¢ä¸º PIL.Image å¯¹è±¡ã€‚
    """
    if isinstance(image_tensor, torch.Tensor):
        print(f"Original tensor shape: {image_tensor.shape}")
        logging.info(f"Original tensor shape: {image_tensor.shape}")

        # å¦‚æœå¼ é‡æœ‰ 4 ä¸ªç»´åº¦ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†æ‰¹æ¬¡ç»´åº¦
        if image_tensor.ndim == 4:
            # æ£€æŸ¥æ‰¹æ¬¡ç»´åº¦æ˜¯å¦ä¸º 1
            if image_tensor.shape[0] == 1:
                image_tensor = image_tensor.squeeze(0)
                print(f"After squeezing batch dimension: {image_tensor.shape}")
                logging.info(f"After squeezing batch dimension: {image_tensor.shape}")
            else:
                # å¦‚æœæ‰¹æ¬¡ç»´åº¦å¤§äº 1ï¼Œæˆ‘ä»¬åªå¤„ç†ç¬¬ä¸€ä¸ªæ ·æœ¬
                image_tensor = image_tensor[0]
                print(f"Selected first sample from batch: {image_tensor.shape}")
                logging.info(f"Selected first sample from batch: {image_tensor.shape}")

        # ç°åœ¨ï¼Œimage_tensor åº”è¯¥æ˜¯ 3 ç»´çš„
        if image_tensor.ndim == 3:
            print(f"Processing 3D tensor with shape: {image_tensor.shape}")
            logging.info(f"Processing 3D tensor with shape: {image_tensor.shape}")

            # åˆ¤æ–­é€šé“ç»´çš„ä½ç½®
            if image_tensor.shape[0] <= 4:
                # é€šé“åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ [C, H, W]
                image_numpy = image_tensor.permute(1, 2, 0).cpu().numpy()
            elif image_tensor.shape[2] <= 4:
                # é€šé“åœ¨æœ€åä¸€ä¸ªç»´åº¦ [H, W, C]
                image_numpy = image_tensor.cpu().numpy()
            else:
                raise ValueError(f"æ— æ³•è§£é‡Šå¼ é‡å½¢çŠ¶: {image_tensor.shape}")

            print(f"image_numpy.shape: {image_numpy.shape}")
            logging.info(f"image_numpy.shape: {image_numpy.shape}")

            # ç¼©æ”¾åˆ° 0-255 å¹¶è½¬æ¢ä¸º uint8
            image_numpy = (image_numpy * 255).clip(0, 255).astype(np.uint8)

            # å¤„ç†ä¸åŒçš„é€šé“æ•°
            if image_numpy.shape[2] == 1:
                image_numpy = image_numpy.squeeze(2)
                return Image.fromarray(image_numpy, mode='L')
            elif image_numpy.shape[2] == 3:
                return Image.fromarray(image_numpy, mode='RGB')
            elif image_numpy.shape[2] == 4:
                return Image.fromarray(image_numpy, mode='RGBA')
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„é€šé“æ•°: {image_numpy.shape[2]}")

        elif image_tensor.ndim == 2:
            # ç°åº¦å›¾åƒ
            image_numpy = image_tensor.cpu().numpy()
            image_numpy = (image_numpy * 255).clip(0, 255).astype(np.uint8)
            return Image.fromarray(image_numpy, mode='L')

        else:
            raise ValueError(f"æ— æ³•å¤„ç†å¼ é‡ç»´åº¦: {image_tensor.ndim}")

    else:
        raise TypeError("è¾“å…¥å¿…é¡»æ˜¯ torch.Tensor ç±»å‹çš„å›¾åƒå¼ é‡ã€‚")

class Manual_MetadataInput:
    """
    Manual_MetadataInput

    ä¸€ä¸ªç”¨äºæ‰‹åŠ¨å¡«å†™å…ƒæ•°æ®å‚æ•°å¹¶è¾“å‡ºå…ƒæ•°æ®å­—å…¸çš„èŠ‚ç‚¹ï¼ŒåŒæ—¶æ”¯æŒè‡ªåŠ¨è·å–å›¾ç‰‡å°ºå¯¸ã€‚
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "placeholder": "è¾“å…¥æç¤ºè¯ï¼ˆpromptï¼‰",
                }),
                "å›¾åƒ": ("IMAGE", {  # å°†å›¾ç‰‡è¾“å…¥è®¾ç½®ä¸ºå¿…å¡«é¡¹
                    "description": "è¾“å…¥å›¾ç‰‡ï¼Œç”¨äºè‡ªåŠ¨è·å–å°ºå¯¸",
                }),
            },
            "optional": {
                "steps": ("INT", {
                    "default": 10,  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "min": 1,
                    "max": 1000,
                }),
                "sampler": ("STRING", {
                    "default": "Euler",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥é‡‡æ ·å™¨åç§°",
                }),
                "schedule_type": ("STRING", {
                    "default": "Simple",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥è°ƒåº¦ç±»å‹ï¼ˆSchedule typeï¼‰",
                }),
                "cfg_scale": ("FLOAT", {
                    "default": 1.0,  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "min": 0.0,
                    "max": 100.0,
                }),
                "distilled_cfg_scale": ("FLOAT", {
                    "default": 3.5,  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "min": 0.0,
                    "max": 100.0,
                }),
                "seed": ("INT", {
                    "default": 1173957321,  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "min": 0,
                    "max": 4294967295,
                }),
                "model_hash": ("STRING", {
                    "default": "9965eb995e",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥æ¨¡å‹å“ˆå¸Œå€¼",
                }),
                "model": ("STRING", {
                    "default": "kimVixen_fp8_e4m3fn",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥æ¨¡å‹åç§°",
                }),
                "lora_hashes": ("STRING", {
                    "default": '"flux_loraName: e3b0c44298fc"',  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥ Lora å“ˆå¸Œå€¼",
                }),
                "version": ("STRING", {
                    "default": "",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥ç‰ˆæœ¬ä¿¡æ¯",
                }),
                "module_1": ("STRING", {
                    "default": "ae",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥æ¨¡å— 1 ä¿¡æ¯",
                }),
                "module_2": ("STRING", {
                    "default": "clip_l",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥æ¨¡å— 2 ä¿¡æ¯",
                }),
                "module_3": ("STRING", {
                    "default": "t5xxl_fp16",  # ä»æ ·æœ¬ä¸­è·å–çš„é»˜è®¤å€¼
                    "placeholder": "è¾“å…¥æ¨¡å— 3 ä¿¡æ¯",
                }),
            }
        }

    RETURN_TYPES = ("DICT",)
    RETURN_NAMES = ("è¾“å‡ºå…ƒæ•°æ®",)
    FUNCTION = "generate_metadata"
    CATEGORY = "ğŸŠ Kim-Nodes/ğŸ”¢Metadata | å…ƒæ•°æ®å¤„ç†"

    def __init__(self):
        pass

    def generate_metadata(self, prompt: str, å›¾åƒ: torch.Tensor,
                         steps: int = 10, sampler: str = "Euler", schedule_type: str = "Simple",
                         cfg_scale: float = 1.0, distilled_cfg_scale: float = 3.5, seed: int = 1173957321,
                         model_hash: str = "9965eb995e",
                         model: str = "kimVixen_fp8_e4m3fn",
                         lora_hashes: str = '"flux_loraName: e3b0c44298fc"',
                         version: str = "",
                         module_1: str = "ae", module_2: str = "clip_l",
                         module_3: str = "t5xxl_fp16") -> Tuple[dict]:
        """
        ç”Ÿæˆå…ƒæ•°æ®å­—å…¸ã€‚
        """
        try:
            print("Manual_MetadataInput èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œã€‚")
            logging.info("Manual_MetadataInput èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œã€‚")

            # è‡ªåŠ¨è·å–å›¾ç‰‡å°ºå¯¸
            try:
                pil_image = tensor2pil(å›¾åƒ)
                width, height = pil_image.size
                size = f"{width}x{height}"
                print(f"è‡ªåŠ¨è·å–å›¾ç‰‡å°ºå¯¸: {size}")
                logging.info(f"è‡ªåŠ¨è·å–å›¾ç‰‡å°ºå¯¸: {size}")
            except Exception as e:
                logging.error(f"è‡ªåŠ¨è·å–å›¾ç‰‡å°ºå¯¸å¤±è´¥: {e}")
                print(f"è‡ªåŠ¨è·å–å›¾ç‰‡å°ºå¯¸å¤±è´¥: {e}")
                # å¦‚æœè·å–å°ºå¯¸å¤±è´¥ï¼Œè®¾ç½®ä¸€ä¸ªé»˜è®¤å€¼æˆ–æŠ›å‡ºå¼‚å¸¸
                size = "1024x1024"  # æˆ–è€…æ ¹æ®éœ€æ±‚å¤„ç†
                print(f"ä½¿ç”¨é»˜è®¤å°ºå¯¸: {size}")
                logging.info(f"ä½¿ç”¨é»˜è®¤å°ºå¯¸: {size}")

            # æ„å»ºå‚æ•°åˆ—è¡¨
            parameters_list = []

            # æ·»åŠ å‚æ•°åˆ°åˆ—è¡¨
            parameters_list.append(f"Steps: {steps}")
            parameters_list.append(f"Sampler: {sampler}")
            parameters_list.append(f"Schedule type: {schedule_type}")
            parameters_list.append(f"CFG scale: {cfg_scale}")
            parameters_list.append(f"Distilled CFG Scale: {distilled_cfg_scale}")
            parameters_list.append(f"Seed: {seed}")
            parameters_list.append(f"Size: {size}")
            if model_hash:
                parameters_list.append(f"Model hash: {model_hash}")
            if model:
                parameters_list.append(f"Model: {model}")
            if lora_hashes:
                parameters_list.append(f"Lora hashes: {lora_hashes}")
            if version:
                parameters_list.append(f"Version: {version}")
            if module_1:
                parameters_list.append(f"Module 1: {module_1}")
            if module_2:
                parameters_list.append(f"Module 2: {module_2}")
            if module_3:
                parameters_list.append(f"Module 3: {module_3}")

            # å°†å‚æ•°åˆ—è¡¨ç»„åˆæˆå­—ç¬¦ä¸²
            parameters_string = ', '.join(parameters_list)

            # ç»„åˆæç¤ºè¯å’Œå‚æ•°
            full_parameters = f"{prompt}\n{parameters_string}"

            # åˆ›å»ºå…ƒæ•°æ®å­—å…¸ï¼Œä½¿ç”¨ 'Parameters' ä½œä¸ºé”®
            metadata = {'Parameters': full_parameters}

            print("å…ƒæ•°æ®ç”ŸæˆæˆåŠŸã€‚")
            logging.info("å…ƒæ•°æ®ç”ŸæˆæˆåŠŸã€‚")

            return (metadata,)

        except Exception as e:
            logging.error(f"å‘ç”Ÿå¼‚å¸¸: {e}")
            print(f"å‘ç”Ÿå¼‚å¸¸: {e}")
            return ()
