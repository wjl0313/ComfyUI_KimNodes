import numpy as np
import cv2
import torch
import math

from PIL import ImageEnhance, Image
from .Filter_algorithm.apply_sharpen import apply_sharpen
from .Filter_algorithm.apply_dehaze import apply_dehaze
from .Filter_algorithm.apply_clahe import apply_clahe
from .Filter_algorithm.adjust_natural_saturation import adjust_natural_saturation
from .Filter_algorithm.adjust_gamma import adjust_gamma

class KimFilter:
    """
    ä¸€ä¸ªå›¾åƒå¤„ç†èŠ‚ç‚¹ï¼Œå¯¹å›¾åƒåº”ç”¨é”åŒ–ã€å»é›¾æ•ˆæœã€CLAHEã€è‡ªç„¶é¥±å’Œåº¦è°ƒæ•´åŠä¼½é©¬è°ƒæ•´ã€‚
    """

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {
                    "description": "ä¸Šä¼ æ‚¨æƒ³åº”ç”¨é«˜çº§å›¾åƒå¤„ç†æ•ˆæœçš„å›¾åƒã€‚"
                }),
                "UMéé”åŒ–æ©è”½": ("FLOAT", {
                    "default": 1.2,
                    "min": 0.0,
                    "max": 3.0,
                    "step": 0.01,
                    "description": "é”åŒ–å¼ºåº¦ï¼Œä»0åˆ°3ã€‚"
                }),
                "DCPæš—é€šé“å…ˆéªŒ": ("FLOAT", {
                    "default": 0.32,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "description": "å»é›¾å¼ºåº¦ï¼Œä»0åˆ°1ã€‚"
                }),
                "CLAHEå¯¹æ¯”åº¦å¢å¼ºé™åˆ¶": ("FLOAT", {
                    "default": 0,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.01,
                    "description": "CLAHEçš„clip limitï¼Œä»0åˆ°4ã€‚"
                }),
                "è‡ªç„¶é¥±å’Œåº¦": ("FLOAT", {
                    "default": 1.1,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.01,
                    "description": "é¥±å’Œåº¦å¼ºåº¦ï¼Œä»0åˆ°2ã€‚"
                }),
                "ä¼½é©¬å€¼": ("FLOAT", {
                    "default": 1.1,
                    "min": 0.1,
                    "max": 3.0,
                    "step": 0.01,
                    "description": "ä¼½é©¬å€¼ï¼Œä»0.1åˆ°3.0ã€‚"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "execute"
    CATEGORY = "ğŸŠ Kim-Nodes/ğŸ¨Filter | æ»¤é•œ"

    def execute(self, image, UMéé”åŒ–æ©è”½, DCPæš—é€šé“å…ˆéªŒ, CLAHEå¯¹æ¯”åº¦å¢å¼ºé™åˆ¶, è‡ªç„¶é¥±å’Œåº¦, ä¼½é©¬å€¼, clahe_tile_grid_size=1):
        # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
        image = self.ensure_image_format(image)
        
        # å¤šæ‰¹æ¬¡å¤„ç†
        batch_size = image.shape[0]
        processed_images = []

        for i in range(batch_size):
            single_image = image[i]
            processed_image = self.process_single_image(single_image, UMéé”åŒ–æ©è”½, DCPæš—é€šé“å…ˆéªŒ, CLAHEå¯¹æ¯”åº¦å¢å¼ºé™åˆ¶, è‡ªç„¶é¥±å’Œåº¦, ä¼½é©¬å€¼, clahe_tile_grid_size)
            processed_images.append(processed_image)

        # åˆå¹¶æ‰€æœ‰å¤„ç†åçš„å›¾åƒ
        processed_images = torch.stack(processed_images)
        return [processed_images]

    def process_single_image(self, image, UMéé”åŒ–æ©è”½, DCPæš—é€šé“å…ˆéªŒ, CLAHEå¯¹æ¯”åº¦å¢å¼ºé™åˆ¶, è‡ªç„¶é¥±å’Œåº¦, ä¼½é©¬å€¼, clahe_tile_grid_size):
        try:
            processed_image = self.apply_effects(image, UMéé”åŒ–æ©è”½, DCPæš—é€šé“å…ˆéªŒ, CLAHEå¯¹æ¯”åº¦å¢å¼ºé™åˆ¶, è‡ªç„¶é¥±å’Œåº¦, ä¼½é©¬å€¼, clahe_tile_grid_size)

            # ç¡®ä¿å›¾åƒæ ¼å¼æ˜¯ torch.Tensor å¹¶å½’ä¸€åŒ–åˆ° [0, 1]
            processed_image = torch.from_numpy(processed_image).float() / 255.0
            return processed_image
        except Exception as e:
            print("åœ¨å›¾åƒå¤„ç†ä¸­å‘ç”Ÿé”™è¯¯:", str(e))
            black_image = torch.zeros((3, image.shape[1], image.shape[2]), dtype=torch.float32)
            return black_image

    def ensure_image_format(self, image):
        if isinstance(image, torch.Tensor):
            image = image.numpy() * 255
            image = image.astype(np.uint8)
        elif isinstance(image, np.ndarray):
            image = image.astype(np.uint8)
        return image

    def apply_effects(self, image, UMéé”åŒ–æ©è”½, DCPæš—é€šé“å…ˆéªŒ, CLAHEå¯¹æ¯”åº¦å¢å¼ºé™åˆ¶, è‡ªç„¶é¥±å’Œåº¦, ä¼½é©¬å€¼, clahe_tile_grid_size):
        image = apply_sharpen(image, UMéé”åŒ–æ©è”½)
        image = apply_dehaze(image, DCPæš—é€šé“å…ˆéªŒ)
        image = apply_clahe(image, CLAHEå¯¹æ¯”åº¦å¢å¼ºé™åˆ¶, (clahe_tile_grid_size, clahe_tile_grid_size))
        image = adjust_natural_saturation(image, è‡ªç„¶é¥±å’Œåº¦)
        image = adjust_gamma(image, ä¼½é©¬å€¼)
        return image
