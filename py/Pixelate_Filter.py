import numpy as np
import cv2
import torch
import torchvision.transforms as T

class Pixelate_Filter:
    """
    ä¸€ä¸ªå›¾åƒå¤„ç†èŠ‚ç‚¹ï¼Œå°†å›¾åƒè½¬æ¢ä¸ºåƒç´ ç”»æ•ˆæœã€‚
    """

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {
                    "description": "è¾“å…¥å›¾åƒã€‚"
                }),
                "mode": (["lanczos4", "contrast"], {
                    "default": "lanczos4",
                    "description": "åƒç´ åŒ–æ¨¡å¼ã€‚lanczos4ï¼šé«˜è´¨é‡ç¼©æ”¾ï¼›contrastï¼šå¯¹æ¯”åº¦ä¿ç•™ã€‚"
                }),
                "size": ("INT", {
                    "default": 128,
                    "min": 32,
                    "max": 256,
                    "step": 4,
                    "description": "ç›®æ ‡å°ºå¯¸ï¼ˆè¾ƒé•¿è¾¹å°†è¢«ç¼©æ”¾åˆ°è¿™ä¸ªå°ºå¯¸ï¼‰ã€‚"
                }),
                "block_size": ("INT", {
                    "default": 16,
                    "min": 4,
                    "max": 32,
                    "step": 2,
                    "description": "åƒç´ å—å¤§å°ï¼ˆä»…åœ¨contrastæ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰ã€‚"
                }),
                "edge_thickness": ("INT", {
                    "default": 4,
                    "min": 1,
                    "max": 16,
                    "step": 1,
                    "description": "åƒç´ è¾¹ç¼˜åšåº¦ï¼ˆä»…åœ¨contrastæ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰ã€‚"
                }),
                "colors": ("INT", {
                    "default": 128,
                    "min": 2,
                    "max": 256,
                    "step": 1,
                    "description": "é¢œè‰²æ•°é‡ï¼Œå‡å°‘å¯è·å¾—æ›´å¤å¤çš„æ•ˆæœã€‚"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "execute"
    CATEGORY = "ğŸ’ Kim-Nodes/ğŸ¨Filter | æ»¤é•œ"

    def execute(self, image, mode, size, block_size, edge_thickness, colors):
        # å°†è¾“å…¥è½¬æ¢ä¸ºæ­£ç¡®çš„æ ¼å¼
        image = image.clone().mul(255).clamp(0, 255).byte().cpu().numpy()
        output = []

        # å¤„ç†æ¯å¼ å›¾ç‰‡
        if len(image.shape) == 4:  # æ‰¹å¤„ç†
            for img in image:
                if mode == "contrast":
                    # ä½¿ç”¨ pixeloe çš„ contrast æ¨¡å¼
                    processed = self.process_contrast(img, size, block_size, edge_thickness, colors)
                else:
                    # ä½¿ç”¨è‡ªå®šä¹‰çš„ lanczos4 æ¨¡å¼
                    processed = self.process_lanczos4(img, size, colors)
                output.append(processed)
        else:  # å•å¼ å›¾ç‰‡
            if mode == "contrast":
                processed = self.process_contrast(image, size, block_size, edge_thickness, colors)
            else:
                processed = self.process_lanczos4(image, size, colors)
            output.append(processed)

        # å †å å¹¶è°ƒæ•´ç»´åº¦é¡ºåº
        output = torch.stack(output, dim=0).permute([0, 2, 3, 1])
        return (output,)

    def process_contrast(self, image, size, block_size, edge_thickness, colors):
        """ä½¿ç”¨ pixeloe çš„ contrast æ¨¡å¼å¤„ç†å›¾åƒ"""
        from pixeloe.pixelize import pixelize
        
        # ä½¿ç”¨ pixeloe è¿›è¡Œåƒç´ åŒ–
        img = pixelize(image,
                    mode="contrast",
                    target_size=size,
                    patch_size=block_size,
                    thickness=edge_thickness,
                    contrast=1.0,
                    saturation=1.0,
                    color_matching=True,  # é»˜è®¤å¯ç”¨é¢œè‰²åŒ¹é…
                    no_upscale=False)  # é»˜è®¤å¯ç”¨æ”¾å¤§
        
        # åº”ç”¨é¢œè‰²é‡åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if colors < 256:
            img = self.quantize_colors(np.array(img), colors)
        
        # è½¬æ¢ä¸º tensor
        return T.ToTensor()(img)

    def process_lanczos4(self, image, size, colors):
        """ä½¿ç”¨ lanczos4 æ¨¡å¼å¤„ç†å›¾åƒ"""
        # è·å–åŸå§‹å°ºå¯¸
        h, w = image.shape[:2]
        
        # è®¡ç®—ç›®æ ‡å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”
        if h > w:
            new_h = size
            new_w = int(w * size / h)
        else:
            new_w = size
            new_h = int(h * size / w)
        
        # ä½¿ç”¨ LANCZOS4 ç¼©å°å›¾åƒ
        small_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        # åº”ç”¨é¢œè‰²é‡åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if colors < 256:
            small_image = self.quantize_colors(small_image, colors)
        
        # æ”¾å¤§å›åŸå§‹å°ºå¯¸ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        small_image = cv2.resize(small_image, (w, h), interpolation=cv2.INTER_NEAREST)
        
        # è½¬æ¢ä¸º tensor
        return T.ToTensor()(small_image)

    def quantize_colors(self, image, colors):
        """å‡å°‘é¢œè‰²æ•°é‡ä»¥è·å¾—æ›´å¤å¤çš„åƒç´ ç”»æ•ˆæœ"""
        # è®¡ç®—æ¯ä¸ªé€šé“çš„é‡åŒ–å› å­
        factor = 256 / colors
        
        # é‡åŒ–é¢œè‰²
        quantized = np.round(image / factor) * factor
        
        # ç¡®ä¿å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
        quantized = np.clip(quantized, 0, 255).astype(np.uint8)
        
        return quantized 